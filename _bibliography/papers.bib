@inproceedings{rothe2025ciss,
  title={Resource and Performance Improvements of Optimized Convolutional Neural Networks for FPGA Implementations of Automatic Modulation Recognition},
  author={Rothe, Joshua A. and Shajaiah, Haya},
  booktitle={2025 59th Annual Conference on Information Sciences and Systems (CISS)},
  pages={1--6},
  year={2025},
  organization={IEEE},
  address={Baltimore, MD, USA},
  doi={10.1109/CISS64860.2025.10944746},
  url={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10944746&isnumber=10944638},
  abstract={Automatic Modulation Recognition (AMR), commonly found in software defined radios, relies on speed and accuracy to effectively interpret the modulation type of incoming signals. Convolutional Neural Networks (CNNs) are growing in popularity over traditional algorithms due to their excellent performance with classification-type problems -- but these are typically resource intensive, and Radio Frequency (RF) receivers are typically part of a larger system that can benefit from less resources being tied to this classification task. Field Programmable Gate Array (FPGA) implementations provide better performance than CPU and GPU implementations in most cases, and the added benefit of these functions being off the processor allows the entire system to perform better. Since resource utilization is such a critical component of effective CNN implementation, and it is often inversely tied to performance, the effectiveness of various hardware optimization techniques as well as their effects on performance should be considered by the designer. This work evaluates the tradeoffs of various model optimizations and how they affect both implementation and performance, synthesizing the models using Xilinx's quantization-aware FINN library. In this work, a methodology is presented for the generation of I and Q signals for CNN model training and evaluation, and the performance and hardware utilization benchmarks are evaluated to determine both design considerations and effective approaches for optimizing these models for real-world implementation.},
  keywords={Training, Software algorithms, Modulation, Logic gates, Hardware, Convolutional neural networks, Resource management, Field programmable gate arrays, Optimization, Software radio, Field Programmable Gate Array (FPGA), Convolutional Neural Network (CNN), Quantization, Structured Pruning, Automatic Modulation Detection/Recognition (AMD/AMR), Rectified Linear Unit (ReLU)},
  selected={true},
  preview={2025_ciss_rothe_preview.png},
  pdf={ciss2025_rothej.pdf},
  slides={ciss2025_rothej_slides.pdf}
}

@mastersthesis{rothe2024thesis,
  title={Quantization and Pruning of Convolutional Neural Networks for Efficient FPGA Implementation of Digital Modulation Detection Firmware},
  author={Rothe, Joshua Andrew},
  year={2024},
  school={Johns Hopkins University},
  address={Baltimore, MD, USA},
  type={Master's Thesis},
  month={July},
  url={https://jscholarship.library.jhu.edu/handle/1774.2/69928},
  html={https://jscholarship.library.jhu.edu/handle/1774.2/69928},
  abstract={Automatic modulation detection is an important function of communications systems. Commonly found in software defined radios, it enables radio receivers to interpret multiple and potentially changing modulation types without needing manual input from the user. Due to vastly increasing performance, many modern systems are moving away from the traditional two-stage process of feature extraction and classification; instead, a neural-network based system (also known as deep learning) is being utilized with increased speed and virtually no loss in accuracy. These implementations, when placed on hardware or on a Field Programmable Gate Array (FPGA), provide the fastest performance; but until recently the barrier of entry has been the size of the neural networks and the infeasible amount of resources they would need to occupy on the FPGA fabric. This thesis explores the effects of both quantization and pruning on convolutional neural network models of various sizes while maintaining high classification accuracy for the digitally modulated signals generated. In this thesis, a framework is proposed for the generation of the signals, models, and hardware estimation to serve as a guide for efficient deep learning implementations of models intended to fit on hardware with limited resources. The results demonstrate tradeoffs and design considerations that balance performance and implementation size for engineers aiming to implement a deep learning-based automatic modulation detection scheme on FPGAs.},
  keywords={Field Programmable Gate Array (FPGA), Convolutional Neural Network (CNN), Quantization, Structured Pruning, Automatic Modulation Detection (AMD/AMR), Rectified Linear Unit (ReLU)},
  selected={true},
  preview={thesis_2024_preview.png},
  pdf={rothe-thesis-2024.pdf}
}